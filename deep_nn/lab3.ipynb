{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5121a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neural import MLPptorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b48af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция обучения\n",
    "def train(x, y, num_iter):\n",
    "    for i in range(0,num_iter):\n",
    "        pred = net.forward(x)\n",
    "        loss = lossFn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%(num_iter/10)==0:\n",
    "           #print(optimizer.param_groups[-1]['lr'])\n",
    "           print('Ошибка на ' + str(i) + ' итерации: ', loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc53b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "X = df.iloc[0:100, 0:3].values\n",
    "y = df.iloc[0:100, 4]\n",
    "y = y.map({'Iris-setosa': 1, 'Iris-virginica': 2, 'Iris-versicolor':3}).values.reshape(-1,1)\n",
    "Y = np.zeros((y.shape[0], np.unique(y).shape[0]))\n",
    "for i in np.unique(y):\n",
    "    Y[:,i-1] = np.where(y == i, 1, 0).reshape(1,-1)\n",
    "\n",
    "X_test = df.iloc[100:150, 0:3].values\n",
    "y = df.iloc[100:150, 4]\n",
    "y = y.map({'Iris-setosa': 1, 'Iris-virginica': 2, 'Iris-versicolor':3}).values.reshape(-1,1)\n",
    "Y_test = np.zeros((y.shape[0], np.unique(y).shape[0]))\n",
    "for i in np.unique(y):\n",
    "    Y_test[:,i-1] = np.where(y == i, 1, 0).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66783a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPptorch(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=50, out_features=3, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Ошибка на 0 итерации:  0.25991252064704895\n",
      "Ошибка на 500 итерации:  0.022043487057089806\n",
      "Ошибка на 1000 итерации:  0.02139892242848873\n",
      "Ошибка на 1500 итерации:  0.01884395256638527\n",
      "Ошибка на 2000 итерации:  0.013337817043066025\n",
      "Ошибка на 2500 итерации:  0.013338174670934677\n",
      "Ошибка на 3000 итерации:  0.013426289893686771\n",
      "Ошибка на 3500 итерации:  0.013333229348063469\n",
      "Ошибка на 4000 итерации:  0.013333248905837536\n",
      "Ошибка на 4500 итерации:  0.01333322562277317\n",
      "[0. 2. 2.]\n",
      "[0. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "inputSize = X.shape[1] # количество входных сигналов равно количеству признаков задачи \n",
    "hiddenSizes = 50 # задаем число нейронов скрытого слоя \n",
    "outputSize = Y.shape[1] if len(Y.shape) else 1 # количество выходных сигналов равно количеству классов задачи\n",
    "\n",
    "\n",
    "net = MLPptorch(inputSize,hiddenSizes,outputSize)\n",
    "print(net)\n",
    "lossFn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.05)\n",
    "\n",
    "# как работает регуляризация\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.05, weight_decay=0.1)\n",
    "\n",
    "loss_ = train(torch.from_numpy(X.astype(np.float32)), \n",
    "              torch.from_numpy(Y.astype(np.float32)), 5000)\n",
    "\n",
    "# for name, param in net.named_parameters():\n",
    "#     print(name, param)\n",
    "\n",
    "pred = net.forward(torch.from_numpy(X.astype(np.float32))).detach().numpy()\n",
    "err = sum(abs((pred>0.5)-Y))\n",
    "print(err)   \n",
    "\n",
    "pred = net.forward(torch.from_numpy(X_test.astype(np.float32))).detach().numpy()\n",
    "err = sum(abs((pred>0.5)-Y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23f7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_ import MLPptorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f51bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPptorch(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Ошибка на 0 итерации:  0.5171573758125305\n",
      "Ошибка на 500 итерации:  0.06660741567611694\n",
      "Ошибка на 1000 итерации:  0.04604059085249901\n",
      "Ошибка на 1500 итерации:  0.040344227105379105\n",
      "Ошибка на 2000 итерации:  0.04269195720553398\n",
      "Ошибка на 2500 итерации:  0.03715496510267258\n",
      "Ошибка на 3000 итерации:  0.03170688822865486\n",
      "Ошибка на 3500 итерации:  0.028227172791957855\n",
      "Ошибка на 4000 итерации:  0.02864379622042179\n",
      "Ошибка на 4500 итерации:  0.024732796475291252\n",
      "[0. 3. 3.]\n",
      "[0. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "net = MLPptorch(inputSize,hiddenSizes,outputSize)\n",
    "print(net)\n",
    "lossFn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.0005)\n",
    "\n",
    "# как работает регуляризация\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.05, weight_decay=0.1)\n",
    "\n",
    "loss_ = train(torch.from_numpy(X.astype(np.float32)), \n",
    "              torch.from_numpy(Y.astype(np.float32)), 5000)\n",
    "\n",
    "# for name, param in net.named_parameters():\n",
    "#     print(name, param)\n",
    "\n",
    "pred = net.forward(torch.from_numpy(X.astype(np.float32))).detach().numpy()\n",
    "err = sum(abs((pred>0.5)-Y))\n",
    "print(err)   \n",
    "\n",
    "pred = net.forward(torch.from_numpy(X_test.astype(np.float32))).detach().numpy()\n",
    "err = sum(abs((pred>0.5)-Y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8c3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод - класс многослойного перцептрона MLPptorch обучается с функцией активации Sigmoid со скоростью обучения = .05\n",
    "# и с функцией активации Relu со скоростью обучения = .0005.\n",
    "# имеет схожие результаты, но у relu веса не имеют ограничений в области положительных значений,\n",
    "# поэтому необходимо выбирать более низкую скорость обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b121ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
